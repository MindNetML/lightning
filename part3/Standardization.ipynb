{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: watermark in /usr/local/lib/python3.9/dist-packages (2.4.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from watermark) (66.1.1)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.9/dist-packages (from watermark) (6.0.0)\n",
      "Requirement already satisfied: ipython>=6.0 in /usr/local/lib/python3.9/dist-packages (from watermark) (8.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=1.4->watermark) (3.11.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython>=6.0->watermark) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.9/dist-packages (from ipython>=6.0->watermark) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/dist-packages (from ipython>=6.0->watermark) (0.1.6)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.9/dist-packages (from ipython>=6.0->watermark) (2.14.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython>=6.0->watermark) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in /usr/local/lib/python3.9/dist-packages (from ipython>=6.0->watermark) (3.0.36)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.9/dist-packages (from ipython>=6.0->watermark) (0.6.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/dist-packages (from ipython>=6.0->watermark) (0.18.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython>=6.0->watermark) (4.8.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython>=6.0->watermark) (0.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython>=6.0->watermark) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect>4.3->ipython>=6.0->watermark) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython>=6.0->watermark) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from stack-data->ipython>=6.0->watermark) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from stack-data->ipython>=6.0->watermark) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.9/dist-packages (from stack-data->ipython>=6.0->watermark) (0.2.2)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from asttokens>=2.1.0->stack-data->ipython>=6.0->watermark) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.9.16\n",
      "IPython version      : 8.5.0\n",
      "\n",
      "pandas    : 1.5.0\n",
      "numpy     : 1.23.4\n",
      "matplotlib: 3.6.1\n",
      "torch     : 1.12.1+cu116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use watermark to keep track of package versions\n",
    "%load_ext watermark\n",
    "%watermark -v -p pandas,numpy,matplotlib,torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2        3  4\n",
       "0  3.62160  8.6661 -2.8073 -0.44699  0\n",
       "1  4.54590  8.1674 -2.4586 -1.46210  0\n",
       "2  3.86600 -2.6383  1.9242  0.10645  0\n",
       "3  3.45660  9.5228 -4.0112 -3.59440  0\n",
       "4  0.32924 -4.4552  4.5718 -0.98880  0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"data_banknote_authentication.txt\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into features and labels\n",
    "X_features = df[[0,1,2,3]].values\n",
    "y_labels = df[4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1372, 4)\n"
     ]
    }
   ],
   "source": [
    "# check shape of features and labels\n",
    "print(X_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([762, 610])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check label distribution\n",
    "np.bincount(y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "\n",
    "        # define features and labels\n",
    "        self.features = torch.tensor(X, dtype = torch.float32)\n",
    "        self.labels = torch.tensor(y, dtype = torch.float32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.features[index]\n",
    "        y = self.labels[index]\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1097"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train size\n",
    "train_size = int(0.8 * len(df))\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation size\n",
    "val_size = X_features.shape[0] - train_size\n",
    "val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use torch.utils to generate dataloader\n",
    "dataset = MyDataset(X_features, y_labels)\n",
    "\n",
    "# split dataset into train and validation\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train dataloader\n",
    "train_loader = DataLoader(dataset = train_set,\n",
    "                          batch_size = 10,\n",
    "                          shuffle = True,\n",
    "                          )\n",
    "\n",
    "# make validation dataloader\n",
    "val_loader = DataLoader(dataset = val_set,\n",
    "                        batch_size = 10,\n",
    "                        shuffle = False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will create the standardization process here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create standardization\n",
    "\n",
    "\n",
    "train_mean = torch.zeros(X_features.shape[1])\n",
    "\n",
    "for x, y in train_loader:\n",
    "    train_mean += x.sum(dim=0)\n",
    "    \n",
    "train_mean /= len(train_set)\n",
    "\n",
    "train_std = torch.zeros(X_features.shape[1])\n",
    "for x, y in train_loader:\n",
    "    train_std += ((x - train_mean)**2).sum(dim=0)\n",
    "\n",
    "train_std = torch.sqrt(train_std / (len(train_set)-1))\n",
    "\n",
    "\n",
    "\n",
    "train_std /= len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature means: tensor([ 0.4858,  2.0245,  1.3277, -1.1991])\n",
      "Feature stds: tensor([0.0026, 0.0054, 0.0039, 0.0019])\n"
     ]
    }
   ],
   "source": [
    "# print mean and std\n",
    "print(f\"Feature means: {train_mean}\")\n",
    "print(f\"Feature stds: {train_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.8454, 5.8915, 4.2544, 2.1216])\n",
      "tensor([ 0.4858,  2.0245,  1.3277, -1.1991])\n"
     ]
    }
   ],
   "source": [
    "# for smaller datasets\n",
    "all_x = []\n",
    "for x, y in train_loader:\n",
    "    all_x.append(x)\n",
    "    \n",
    "train_std = torch.concat(all_x).std(dim=0)\n",
    "train_mean = torch.concat(all_x).mean(dim=0)\n",
    "\n",
    "print(train_std)\n",
    "print(train_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization function\n",
    "def standardize(x, mean, std):\n",
    "    return (x - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement model\n",
    "class LogisticRegression(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(num_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear(x)\n",
    "        preds = torch.sigmoid(logits)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = LogisticRegression(num_features = 4).to(device)\n",
    "\n",
    "# define optimizer\n",
    "optimizer = optim.SGD(params = model.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 000/110 | Loss: 0.63\n",
      "Epoch: 001/010 | Batch 020/110 | Loss: 0.54\n",
      "Epoch: 001/010 | Batch 040/110 | Loss: 0.38\n",
      "Epoch: 001/010 | Batch 060/110 | Loss: 0.14\n",
      "Epoch: 001/010 | Batch 080/110 | Loss: 0.41\n",
      "Epoch: 001/010 | Batch 100/110 | Loss: 0.11\n",
      "Epoch: 002/010 | Batch 000/110 | Loss: 0.11\n",
      "Epoch: 002/010 | Batch 020/110 | Loss: 0.18\n",
      "Epoch: 002/010 | Batch 040/110 | Loss: 0.06\n",
      "Epoch: 002/010 | Batch 060/110 | Loss: 0.10\n",
      "Epoch: 002/010 | Batch 080/110 | Loss: 0.13\n",
      "Epoch: 002/010 | Batch 100/110 | Loss: 0.13\n",
      "Epoch: 003/010 | Batch 000/110 | Loss: 0.08\n",
      "Epoch: 003/010 | Batch 020/110 | Loss: 0.08\n",
      "Epoch: 003/010 | Batch 040/110 | Loss: 0.06\n",
      "Epoch: 003/010 | Batch 060/110 | Loss: 0.11\n",
      "Epoch: 003/010 | Batch 080/110 | Loss: 0.12\n",
      "Epoch: 003/010 | Batch 100/110 | Loss: 0.07\n",
      "Epoch: 004/010 | Batch 000/110 | Loss: 0.04\n",
      "Epoch: 004/010 | Batch 020/110 | Loss: 0.04\n",
      "Epoch: 004/010 | Batch 040/110 | Loss: 0.08\n",
      "Epoch: 004/010 | Batch 060/110 | Loss: 0.16\n",
      "Epoch: 004/010 | Batch 080/110 | Loss: 0.08\n",
      "Epoch: 004/010 | Batch 100/110 | Loss: 0.18\n",
      "Epoch: 005/010 | Batch 000/110 | Loss: 0.07\n",
      "Epoch: 005/010 | Batch 020/110 | Loss: 0.11\n",
      "Epoch: 005/010 | Batch 040/110 | Loss: 0.12\n",
      "Epoch: 005/010 | Batch 060/110 | Loss: 0.04\n",
      "Epoch: 005/010 | Batch 080/110 | Loss: 0.04\n",
      "Epoch: 005/010 | Batch 100/110 | Loss: 0.04\n",
      "Epoch: 006/010 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 006/010 | Batch 020/110 | Loss: 0.21\n",
      "Epoch: 006/010 | Batch 040/110 | Loss: 0.10\n",
      "Epoch: 006/010 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 006/010 | Batch 080/110 | Loss: 0.06\n",
      "Epoch: 006/010 | Batch 100/110 | Loss: 0.09\n",
      "Epoch: 007/010 | Batch 000/110 | Loss: 0.05\n",
      "Epoch: 007/010 | Batch 020/110 | Loss: 0.13\n",
      "Epoch: 007/010 | Batch 040/110 | Loss: 0.18\n",
      "Epoch: 007/010 | Batch 060/110 | Loss: 0.19\n",
      "Epoch: 007/010 | Batch 080/110 | Loss: 0.10\n",
      "Epoch: 007/010 | Batch 100/110 | Loss: 0.07\n",
      "Epoch: 008/010 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 008/010 | Batch 020/110 | Loss: 0.06\n",
      "Epoch: 008/010 | Batch 040/110 | Loss: 0.04\n",
      "Epoch: 008/010 | Batch 060/110 | Loss: 0.05\n",
      "Epoch: 008/010 | Batch 080/110 | Loss: 0.05\n",
      "Epoch: 008/010 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 009/010 | Batch 000/110 | Loss: 0.15\n",
      "Epoch: 009/010 | Batch 020/110 | Loss: 0.06\n",
      "Epoch: 009/010 | Batch 040/110 | Loss: 0.05\n",
      "Epoch: 009/010 | Batch 060/110 | Loss: 0.05\n",
      "Epoch: 009/010 | Batch 080/110 | Loss: 0.05\n",
      "Epoch: 009/010 | Batch 100/110 | Loss: 0.16\n",
      "Epoch: 010/010 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 010/010 | Batch 020/110 | Loss: 0.04\n",
      "Epoch: 010/010 | Batch 040/110 | Loss: 0.12\n",
      "Epoch: 010/010 | Batch 060/110 | Loss: 0.05\n",
      "Epoch: 010/010 | Batch 080/110 | Loss: 0.06\n",
      "Epoch: 010/010 | Batch 100/110 | Loss: 0.03\n"
     ]
    }
   ],
   "source": [
    "# define training loop\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (features, class_labels) in enumerate(train_loader):\n",
    "\n",
    "        # standardize features\n",
    "        features = standardize(features, train_mean, train_std)\n",
    "        # make predictions\n",
    "        preds = model(features.to(device))\n",
    "\n",
    "        # calculate loss\n",
    "        loss = F.binary_cross_entropy(preds, class_labels.view(preds.shape).to(device))\n",
    "\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backprop\n",
    "        loss.backward()\n",
    "\n",
    "        # optimizer step (gradient descent)\n",
    "        optimizer.step()\n",
    "\n",
    "        ### LOGGING\n",
    "        if not batch_idx % 20: # every 20 batches\n",
    "            print(f\"Epoch: {epoch+1:03d}/{epochs:03d} | \"\n",
    "                  f\"Batch {batch_idx:03d}/{len(train_loader):03d} | \"\n",
    "                  f\"Loss: {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Accuaracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to compute accuracy\n",
    "def compute_accuracy(model, dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0.0\n",
    "    num_examples = 0\n",
    "\n",
    "    for idx, (features, class_labels) in enumerate(dataloader):\n",
    "        # standardize features\n",
    "        features = standardize(features, train_mean, train_std)\n",
    "        # make predictions\n",
    "        with torch.inference_mode():\n",
    "            pred = model(features.to(device))\n",
    "\n",
    "        # calculate accuracy\n",
    "        preds = torch.where(pred > 0.5, 1, 0)\n",
    "        lab = class_labels.view(preds.shape).to(preds.dtype).to(device)\n",
    "        compare = lab == preds\n",
    "        correct += torch.sum(compare)\n",
    "        num_examples += len(compare)\n",
    "    \n",
    "    return correct / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 97.99%\n",
      "Val Accuray 98.181824%\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy on train and validation\n",
    "train_acc = compute_accuracy(model, train_loader)\n",
    "print(f\"Train Accuracy: {train_acc*100:.2f}%\")\n",
    "\n",
    "train_val = compute_accuracy(model, val_loader)\n",
    "print(f\"Val Accuray {train_val * 100:2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
